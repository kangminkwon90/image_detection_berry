{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import Inception_V3_Weights\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part image extraction and image preprocess for CNN model\n",
    "\n",
    "class PartImageExtractor:\n",
    "    def __init__(self):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(299),\n",
    "            transforms.CenterCrop(299),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        self.model = models.inception_v3(weights=Inception_V3_Weights.DEFAULT)\n",
    "        self.model.eval()\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            self.model = self.model.cuda()\n",
    "\n",
    "    def extract_features(self, image, bbox):\n",
    "        x, y, w, h = bbox\n",
    "        image = Image.open(image)\n",
    "        image = image.crop((x, y, x+w, y+h))\n",
    "        image = self.transform(image)\n",
    "        image = image.unsqueeze(0)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            image = image.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = self.model(image)\n",
    "\n",
    "        return features.cpu().numpy()\n",
    "    \n",
    "    def extract_features_from_array(self, cropped_img_array):\n",
    "        image = Image.fromarray(np.uint8(cropped_img_array))\n",
    "        image = self.transform(image)\n",
    "        image = image.unsqueeze(0)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            image = image.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            features = self.model(image)\n",
    "        \n",
    "        return features.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10 = pd.read_csv('./data_preprocessed/label/train_label_10.csv', encoding='utf-8')\n",
    "train_50 = pd.read_csv('./data_preprocessed/label/train_label_50.csv', encoding='utf-8')\n",
    "train_100 = pd.read_csv('./data_preprocessed/label/train_label_100.csv', encoding='utf-8')\n",
    "test_data = pd.read_csv('./data_preprocessed/label/test_label_third.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>folder_path</th>\n",
       "      <th>file_name</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>class</th>\n",
       "      <th>cause_method</th>\n",
       "      <th>folder_path.1</th>\n",
       "      <th>ei_value</th>\n",
       "      <th>pl_value</th>\n",
       "      <th>...</th>\n",
       "      <th>category_id</th>\n",
       "      <th>disease_status</th>\n",
       "      <th>name</th>\n",
       "      <th>bbox_x</th>\n",
       "      <th>bbox_y</th>\n",
       "      <th>bbox_width</th>\n",
       "      <th>bbox_height</th>\n",
       "      <th>object_status</th>\n",
       "      <th>bbox_id</th>\n",
       "      <th>sampling_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vl_normal_3022</td>\n",
       "      <td>./data_raw/test_image/test_normal/</td>\n",
       "      <td>normal_40_012_221116123827.jpg</td>\n",
       "      <td>1337</td>\n",
       "      <td>2266</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>./data_raw/test_image/test_normal/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>stem</td>\n",
       "      <td>1041.86</td>\n",
       "      <td>1673.6</td>\n",
       "      <td>75.69</td>\n",
       "      <td>109.86</td>\n",
       "      <td>normal</td>\n",
       "      <td>vl_normal_3022_0</td>\n",
       "      <td>vl_sam_10_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          file_id                         folder_path  \\\n",
       "0  vl_normal_3022  ./data_raw/test_image/test_normal/   \n",
       "\n",
       "                        file_name  image_width  image_height   class  \\\n",
       "0  normal_40_012_221116123827.jpg         1337          2266  normal   \n",
       "\n",
       "  cause_method                       folder_path.1  ei_value  pl_value  ...  \\\n",
       "0       normal  ./data_raw/test_image/test_normal/       NaN       NaN  ...   \n",
       "\n",
       "   category_id  disease_status  name   bbox_x  bbox_y bbox_width  bbox_height  \\\n",
       "0            0               N  stem  1041.86  1673.6      75.69       109.86   \n",
       "\n",
       "   object_status           bbox_id  sampling_id  \n",
       "0         normal  vl_normal_3022_0  vl_sam_10_0  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10_copy = train_10.drop('sampling_id', axis=1).copy()\n",
    "train_50_copy = train_50.drop('sampling_id', axis=1).copy()\n",
    "train_100_copy = train_100.drop('sampling_id', axis=1).copy()\n",
    "test_data_copy = test_data.drop('sampling_id', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tr_id_create(df, sampling_volume):\n",
    "    normal = df[df['file_id'].str.contains('normal')].reset_index(drop=True)\n",
    "    blight = df[df['file_id'].str.contains('blight')].reset_index(drop=True)\n",
    "    wilt = df[df['file_id'].str.contains('wilt')].reset_index(drop=True)\n",
    "    scorch = df[df['file_id'].str.contains('scorch')].reset_index(drop=True)\n",
    "    chlorosis = df[df['file_id'].str.contains('chlorosis')].reset_index(drop=True)\n",
    "\n",
    "    part_list = [normal, blight, wilt, scorch, chlorosis]\n",
    "    id_list = ['normal', 'blight', 'wilt', 'scorch', 'chlorosis']\n",
    "\n",
    "    for df, id in zip(part_list, id_list):\n",
    "        df['tr_id'] = None\n",
    "        data_id = id\n",
    "        for idx, _ in df.iterrows():\n",
    "            df.at[idx, 'tr_id'] = f\"tr_{sampling_volume}_{data_id}_{idx}\"\n",
    "\n",
    "    result_df = pd.concat(part_list, axis=0).reset_index(drop=True)\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vl_id_create(df):\n",
    "    normal = df[df['file_id'].str.contains('normal')].reset_index(drop=True)\n",
    "    blight = df[df['file_id'].str.contains('blight')].reset_index(drop=True)\n",
    "    wilt = df[df['file_id'].str.contains('wilt')].reset_index(drop=True)\n",
    "    scorch = df[df['file_id'].str.contains('scorch')].reset_index(drop=True)\n",
    "    chlorosis = df[df['file_id'].str.contains('chlorosis')].reset_index(drop=True)\n",
    "\n",
    "    part_list = [normal, blight, wilt, scorch, chlorosis]\n",
    "    id_list = ['normal', 'blight', 'wilt', 'scorch', 'chlorosis']\n",
    "\n",
    "    for df, id in zip(part_list, id_list):\n",
    "        df['vl_id'] = None\n",
    "        data_id = id\n",
    "        for idx, _ in df.iterrows():\n",
    "            df.at[idx, 'vl_id'] = f\"vl_{data_id}_{idx}\"\n",
    "\n",
    "    result_df = pd.concat(part_list, axis=0).reset_index(drop=True)\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10_with_id = tr_id_create(train_10_copy, '10')\n",
    "train_50_with_id = tr_id_create(train_50_copy, '50')\n",
    "train_100_with_id = tr_id_create(train_100_copy, '100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_10_with_id.to_csv('./data_preprocessed/label/train_label_10.csv', encoding='utf-8', index=False)\n",
    "train_50_with_id.to_csv('./data_preprocessed/label/train_label_50.csv', encoding='utf-8', index=False)\n",
    "train_100_with_id.to_csv('./data_preprocessed/label/train_label_100.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_with_id = vl_id_create(test_data_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11082\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data_with_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_with_id.to_csv('./data_preprocessed/label/test_label_final.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = PartImageExtractor()\n",
    "def part_image_extractor_executor(df, id_col):\n",
    "    features_dict = {}\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing images\"):\n",
    "        folder_path = row['folder_path']\n",
    "        file_name = row['file_name']\n",
    "        bbox = (row['bbox_x'], row['bbox_y'], row['bbox_width'], row['bbox_height'])\n",
    "\n",
    "        image_path = os.path.join(folder_path, file_name)\n",
    "        features = extractor.extract_features(image_path, bbox)\n",
    "        features_id = row[id_col]\n",
    "        features_dict[features_id] = features\n",
    "\n",
    "    print(features_dict[df[id_col][0]].shape)\n",
    "    print(len(features_dict))\n",
    "    print(len(df))\n",
    "    \n",
    "    return features_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 28382/28382 [22:08<00:00, 21.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n",
      "28382\n",
      "28382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_10_features = part_image_extractor_executor(train_10_with_id, 'tr_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 132415/132415 [1:37:40<00:00, 22.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n",
      "132415\n",
      "132415\n"
     ]
    }
   ],
   "source": [
    "train_50_features = part_image_extractor_executor(train_50_with_id, 'tr_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 265496/265496 [3:19:17<00:00, 22.20it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n",
      "265496\n",
      "265496\n"
     ]
    }
   ],
   "source": [
    "train_100_features = part_image_extractor_executor(train_100_with_id, 'tr_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"./data_preprocessed/part_image_features/tr_cropped_features_10_dict.npz\", **train_10_features)\n",
    "np.savez(\"./data_preprocessed/part_image_features/tr_cropped_features_50_dict.npz\", **train_50_features)\n",
    "np.savez(\"./data_preprocessed/part_image_features/tr_cropped_features_100_dict.npz\", **train_100_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 11082/11082 [07:00<00:00, 26.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000)\n",
      "11082\n",
      "11082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_features = part_image_extractor_executor(test_data_with_id, 'vl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"./data_preprocessed/part_image_features/vl_cropped_features_dict.npz\", **test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "berry_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
