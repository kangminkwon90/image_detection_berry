{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label preprocessing code layout\n",
    "\n",
    "\"\"\"\n",
    "*원시 json 라벨 파일들 샘플링 및 지정 폴더에 복사\n",
    "*원시 json 라벨 파일들 병합 -> 단일 데이터프레임\n",
    "*필요 컬럼 추출\n",
    "    *images.fname\n",
    "    *images.width, height\n",
    "    *environments: \"_value\"\n",
    "    *annotations: \"bbox\", \"id\", \"status\" \n",
    "    *categories: \"id\", \"name\"\n",
    "    *disease_class\n",
    "    *disease_cause_method\n",
    "\n",
    "*추출 컬럼 데이터 분리(각 데이터는 딕셔너리 데이터를 요소로 갖는 리스트 형태)\n",
    "    *딕셔너리 변환: json type -> pandas type\n",
    "        *변환 전 type: str\n",
    "        *변환 후 type: list\n",
    "        *변환 case1(None 없는 경우): .replace(\"'\", \"\\\"\")\n",
    "        *변환 case2(None 있는 경우): .replace(\"None\", \"null\").replace(\"'\", \"\\\"\")\n",
    "            *주의: pandas에서도 {'key':'value'}, {'key': None}와 같이 (', None)로 출력되기 때문에 헷갈리기 쉽다. 출력 형태는 같아도 내부에서 인식하는 type이 다름을 유의할 것\n",
    "\n",
    "    *딕셔너리 분리: key, value\n",
    "    *value 변환(문자열 외 다른 데이터형이 필요한 경우): str -> list, number\n",
    "        *str -> list변환: ast.literal_eval(arg)\n",
    "        *str -> num_type변환: 대상 리스트 내에서 num_type(arg) 반복 수행(예: list_num = [float(itme) for item in list if item is not None])\n",
    "        *주의\n",
    "            *위의 과정으로 분리된 value가 리스트 형태일 때, 이 값의 type은 리스트가 아니라 리스트 형태의 문자열이므로, 리스트로 변환하는 작업이 필요하다.\n",
    "            *각 리스트 내에서 '1.5'와 같이 숫자형 데이터가 ''안에 있다면, 숫자형 문자열이므로 숫자형 데이터로 변환하는 작업이 필요하다(자동 변환 안됨)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원시 데이터 샘플링\n",
    "\n",
    "input_path_1 = './data_raw/train_label/TL_01.딸기_001.설향_01.정상'\n",
    "input_path_2 = './data_raw/train_label/TL_01.딸기_001.설향_02.역병'\n",
    "input_path_3 = './data_raw/train_label/TL_01.딸기_001.설향_03.시들음병'\n",
    "input_path_4 = './data_raw/train_label/TL_01.딸기_001.설향_04.잎끝마름'\n",
    "input_path_5 = './data_raw/train_label/TL_01.딸기_001.설향_05.황화'\n",
    "output_path_1 = './data_raw/train_label/sampling_normal'\n",
    "output_path_2 = './data_raw/train_label/sampling_blight'\n",
    "output_path_3 = './data_raw/train_label/sampling_wilt'\n",
    "output_path_4 = './data_raw/train_label/sampling_scorch'\n",
    "output_path_5 = './data_raw/train_label/sampling_chlorosis'\n",
    "\n",
    "input_paths = [input_path_1, input_path_2, input_path_3, input_path_4, input_path_5]\n",
    "output_paths = [output_path_1, output_path_2, output_path_3, output_path_4, output_path_5]\n",
    "num_files = 12000\n",
    "\n",
    "def copy_files(input_path, output_path, num_files=12000):\n",
    "    # output폴더를 여기서 생성하게 할 경우에는 아래의 Path 기능 사용\n",
    "    # Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    files = [f for f in os.listdir(input_path) if f.endswith('.json')]\n",
    "    files_to_copy = files[-num_files:]\n",
    "\n",
    "    for file in files_to_copy:\n",
    "        shutil.copy(os.path.join(input_path, file), os.path.join(output_path, file))\n",
    "\n",
    "    return f\"{len(files_to_copy)} files coppied from {input_path} to {output_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원시 데이터 샘플링 실행\n",
    "\n",
    "copy_results = [copy_files(input_path, output_path, num_files) for input_path, output_path in zip(input_paths, output_paths)]\n",
    "copy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플링한 원시 데이터를 데이터프레임으로 변환 및 병합\n",
    "\n",
    "def json_to_df(folder_path):\n",
    "    df_list = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith('.json'):\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    data = json.load(file)\n",
    "\n",
    "                df_list.append(pd.json_normalize(data))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON in file {filename}: {e}\")\n",
    "\n",
    "    if df_list:\n",
    "        merged_df = pd.concat(df_list, ignore_index=True)\n",
    "    else:\n",
    "        print(\"No valid JSON files found\")\n",
    "\n",
    "    print('merged_df')\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [r'./data_raw/train_label/sampling_normal', r'./data_raw/train_label/sampling_blight',\n",
    "                r'./data_raw/train_label/sampling_wilt', r'./data_raw/train_label/sampling_scorch',\n",
    "                r'./data_raw/train_label/sampling_chlorosis']\n",
    "\n",
    "merged_normal = json_to_df(folder_paths[0])\n",
    "merged_blight = json_to_df(folder_paths[1])\n",
    "merged_wilt = json_to_df(folder_paths[2])\n",
    "merged_scorch = json_to_df(folder_paths[3])\n",
    "merged_chlorosis = json_to_df(folder_paths[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_normal.to_csv('./data_raw/train_label/merged_df/merged_raw_normal.csv', encoding='utf-8', index=False)\n",
    "merged_blight.to_csv('./data_raw/train_label/merged_df/merged_raw_blight.csv', encoding='utf-8', index=False)\n",
    "merged_wilt.to_csv('./data_raw/train_label/merged_df/merged_raw_wilt.csv', encoding='utf-8', index=False)\n",
    "merged_scorch.to_csv('./data_raw/train_label/merged_df/merged_raw_scorch.csv', encoding='utf-8', index=False)\n",
    "merged_chlorosis.to_csv('./data_raw/train_label/merged_df/merged_raw_chlorosis.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터프레임 정제: 필요 컬럼 추출 및 변환\n",
    "\n",
    "raw_normal = pd.read_csv('./data_raw/train_label/merged_df/merged_raw_normal.csv', encoding='utf-8')\n",
    "raw_blight = pd.read_csv('./data_raw/train_label/merged_df/merged_raw_blight.csv', encoding='utf-8')\n",
    "raw_wilt = pd.read_csv('./data_raw/train_label/merged_df/merged_raw_wilt.csv', encoding='utf-8')\n",
    "raw_scorch = pd.read_csv('./data_raw/train_label/merged_df/merged_raw_scorch.csv', encoding='utf-8')\n",
    "raw_chlorosis = pd.read_csv('./data_raw/train_label/merged_df/merged_raw_chlorosis.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요 컬럼 추출\n",
    "col_selection = ['environments', 'annotations', 'categories', 'images.fname', 'images.width', 'images.height', 'images.disease_class', 'images.disease_cause_method']\n",
    "\n",
    "normal_data = raw_normal[col_selection].copy()\n",
    "blight_data = raw_blight[col_selection].copy()\n",
    "wilt_data = raw_wilt[col_selection].copy()\n",
    "scorch_data = raw_scorch[col_selection].copy()\n",
    "chlorosis_data = raw_chlorosis[col_selection].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리 및 변환: environments\n",
    "    # '_value'에 해당하는 값들 분리하여 각각 컬럼으로 할당\n",
    "    # environments의 id는 annotations, categories의 id와 불일치하므로 별도 처리\n",
    "        # environments의 id는 모두 0~4의 값만 가짐: 각 부위에 대한 측정이 아니라, 측정 회차를 의미하는 것으로 추정됨(예: 각 샘플마다 5회 측정)\n",
    "    # 모든 회차의 수치를 컬럼화 하기에는 비효율적이므로, 평균값으로 통일\n",
    "\n",
    "normal_sample = normal_data[:500].copy()\n",
    "\n",
    "def json_data_to_pandas(df, target_col, saving_col):\n",
    "    df[saving_col] = None\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        json_str = row[target_col]\n",
    "        str_corrected = json_str.replace(\"None\", \"null\").replace(\"'\", \"\\\"\")\n",
    "        corrected_data = json.loads(str_corrected)\n",
    "        df.at[idx, saving_col] = corrected_data\n",
    "\n",
    "    dict_format = df[saving_col][0]\n",
    "    extraction_keys = dict_format[0].keys()\n",
    "    key_list = list(extraction_keys)\n",
    "    df_pandas_type = df.drop([target_col], axis=1)\n",
    "\n",
    "    print(type(df[saving_col]))\n",
    "    return df_pandas_type, key_list\n",
    "\n",
    "def extraction_env_values(df_pandas_type, key_list):\n",
    "    df = df_pandas_type\n",
    "    df['value_types'] = None\n",
    "    value_names = []\n",
    "\n",
    "    for i in range(len(key_list)):\n",
    "        candidate = key_list[i]\n",
    "        if candidate.endswith('_value'):\n",
    "            value_names.append(candidate)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        value_dict = {}\n",
    "        dict_list = row['values']\n",
    "        for dictionary in dict_list:\n",
    "            for key, value in dictionary.items():\n",
    "                if key in value_names:\n",
    "                    if key not in value_dict:\n",
    "                        value_dict[key] = [value]\n",
    "                    else:\n",
    "                        value_dict[key].append(value)\n",
    "        df.at[idx, 'value_types'] = value_dict\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        value_to_split = row['value_types']\n",
    "        for key, value in value_to_split.items():\n",
    "            if key not in df.columns:\n",
    "                df[key] = pd.NA\n",
    "            df.at[idx, key] = value\n",
    "\n",
    "    df_splited_env_values = df.drop(['values', 'value_types'], axis=1)\n",
    "    print(df_splited_env_values.columns)\n",
    "    return df_splited_env_values\n",
    "\n",
    "def str_to_num(string_list):\n",
    "    if isinstance(string_list, str):\n",
    "        try:\n",
    "            list_obj = ast.literal_eval(string_list)\n",
    "        except ValueError:\n",
    "            return string_list\n",
    "    else:\n",
    "        list_obj = string_list\n",
    "\n",
    "    if all(item is None for item in list_obj):\n",
    "        return None\n",
    "    else:\n",
    "        list_num = [float(item) for item in list_obj if item is not None]\n",
    "        return list_num\n",
    "    \n",
    "def string_to_number(df):\n",
    "    col_list = [col for col in df.columns if col.endswith('_value')]\n",
    "    \n",
    "    for col in col_list:\n",
    "        df[col] = df[col].apply(str_to_num)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def calculate_avg(df):\n",
    "    col_list = [col for col in df.columns if col.endswith('_value')]\n",
    "\n",
    "    for value_name in col_list:\n",
    "        for idx, row in df.iterrows():\n",
    "            values = row[value_name]\n",
    "            if values is not None:\n",
    "                df.at[idx, value_name] = np.mean(values)\n",
    "\n",
    "            else:\n",
    "                df.at[idx, value_name] = None\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index(['annotations', 'categories', 'images.fname', 'images.width',\n",
      "       'images.height', 'images.disease_class', 'images.disease_cause_method',\n",
      "       'ti_value', 'hi_value', 'ci_value', 'ir_value', 'tl_value', 'ei_value',\n",
      "       'pl_value', 'sr_value', 'cl_value', 'el_value', 'hl_value', 'pi_value',\n",
      "       'rp_value'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "normal_test, env_list = json_data_to_pandas(normal_sample, target_col='environments', saving_col='values')\n",
    "normal_test_env = extraction_env_values(normal_test, env_list)\n",
    "normal_test_values = string_to_number(normal_test_env)\n",
    "normal_test_avg = calculate_avg(normal_test_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_test_avg.to_csv('normal_avg_test.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리 및 변환: annotations, categories\n",
    "    # annotation의 id와 categories의 id-name은 연결되므로 같이 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
