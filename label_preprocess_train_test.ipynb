{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import os\n",
    "import shutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define elements functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## label data sampling and merging\n",
    "\n",
    "def copy_files(input_path, output_path, num_files=12000):\n",
    "    # output폴더를 여기서 생성하게 할 경우에는 아래의 Path 기능 사용\n",
    "    # Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    files = [f for f in os.listdir(input_path) if f.endswith('.json')]\n",
    "    files_to_copy = files[-num_files:]\n",
    "\n",
    "    for file in files_to_copy:\n",
    "        shutil.copy(os.path.join(input_path, file), os.path.join(output_path, file))\n",
    "\n",
    "    return f\"{len(files_to_copy)} files coppied from {input_path} to {output_path}\"\n",
    "\n",
    "def json_to_df(folder_path):\n",
    "    df_list = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if filename.endswith('.json'):\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                    data = json.load(file)\n",
    "\n",
    "                df_list.append(pd.json_normalize(data))\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON in file {filename}: {e}\")\n",
    "\n",
    "    if df_list:\n",
    "        merged_df = pd.concat(df_list, ignore_index=True)\n",
    "    else:\n",
    "        print(\"No valid JSON files found\")\n",
    "\n",
    "    print('merged_df')\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## image data copy and renaming\n",
    "\n",
    "def copy_image_files(src_path, dst_path, df):\n",
    "\n",
    "    file_list = list(df['images.fname'])\n",
    "    files_to_copy = []\n",
    "    for file_src in os.listdir(src_path):\n",
    "        if (file_src in file_list) and (file_src.endswith('.jpg')):\n",
    "            files_to_copy.append(file_src)\n",
    "\n",
    "    for file in files_to_copy:\n",
    "        shutil.copy(os.path.join(src_path, file), os.path.join(dst_path, file))\n",
    "\n",
    "    return f\"{len(files_to_copy)} files coppied from {src_path} to {dst_path}\"\n",
    "\n",
    "def rename_kor_en(df, kor, en, image_path):\n",
    "    df['fname_kor'] = df['images.fname']\n",
    "    df['images.fname']=df['images.fname'].apply(lambda x: x.replace('딸기','berry'))\n",
    "    df['images.fname']=df['images.fname'].apply(lambda x: x.replace('설향','snow'))\n",
    "    df['images.fname']=df['images.fname'].apply(lambda x: x.replace(kor,en))\n",
    "\n",
    "    folder_path = image_path\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        old_file_path = os.path.join(folder_path, row['fname_kor'])\n",
    "        new_file_path = os.path.join(folder_path, row['images.fname'])\n",
    "        try:\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f'Renamed: {old_file_path} to {new_file_path}')\n",
    "        except FileNotFoundError:\n",
    "            print(f'File not found: {old_file_path}')\n",
    "        except FileExistsError:\n",
    "            print(f'File already exists: {new_file_path}')\n",
    "\n",
    "    df_en = df.drop(['fname_kor'], axis=1)\n",
    "    return df_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## selecting columns from raw dataframe\n",
    "\n",
    "def selecting_columns(df, selected_col_list):\n",
    "    df_sel = df[selected_col_list].copy()\n",
    "\n",
    "    return df_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transforming json type dict to pandas type dict\n",
    "\n",
    "def json_data_to_pandas(df, target_col, saving_col):\n",
    "    df[saving_col] = None\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        json_str = row[target_col]\n",
    "        str_corrected = json_str.replace(\"None\", \"null\").replace(\"'\", \"\\\"\")\n",
    "        corrected_data = json.loads(str_corrected)\n",
    "        df.at[idx, saving_col] = corrected_data\n",
    "\n",
    "    dict_format = df[saving_col][0]\n",
    "    extraction_keys = dict_format[0].keys()\n",
    "    key_list = list(extraction_keys)\n",
    "    df_pandas_type = df.drop([target_col], axis=1)\n",
    "\n",
    "    print(type(df[saving_col]))\n",
    "    return df_pandas_type, key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## processing column data: environments\n",
    "\n",
    "def extraction_env_values(df_pandas_type, key_list, target_col):\n",
    "    df = df_pandas_type\n",
    "    df['value_types'] = None\n",
    "    value_names = []\n",
    "\n",
    "    for i in range(len(key_list)):\n",
    "        candidate = key_list[i]\n",
    "        if candidate.endswith('_value'):\n",
    "            value_names.append(candidate)\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        value_dict = {}\n",
    "        dict_list = row[target_col]\n",
    "        for dictionary in dict_list:\n",
    "            for key, value in dictionary.items():\n",
    "                if key in value_names:\n",
    "                    if key not in value_dict:\n",
    "                        value_dict[key] = [value]\n",
    "                    else:\n",
    "                        value_dict[key].append(value)\n",
    "        df.at[idx, 'value_types'] = value_dict\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        value_to_split = row['value_types']\n",
    "        for key, value in value_to_split.items():\n",
    "            if key not in df.columns:\n",
    "                df[key] = pd.NA\n",
    "            df.at[idx, key] = value\n",
    "\n",
    "    df_splited_env_values = df.drop([target_col, 'value_types'], axis=1)\n",
    "    print(df_splited_env_values.columns)\n",
    "    return df_splited_env_values\n",
    "\n",
    "def str_to_num(string_list):\n",
    "    if isinstance(string_list, str):\n",
    "        try:\n",
    "            list_obj = ast.literal_eval(string_list)\n",
    "        except ValueError:\n",
    "            return string_list\n",
    "    else:\n",
    "        list_obj = string_list\n",
    "\n",
    "    if all(item is None for item in list_obj):\n",
    "        return None\n",
    "    else:\n",
    "        list_num = [float(item) for item in list_obj if item is not None]\n",
    "        return list_num\n",
    "    \n",
    "def string_to_number(df):\n",
    "    col_list = [col for col in df.columns if col.endswith('_value')]\n",
    "    \n",
    "    for col in col_list:\n",
    "        df[col] = df[col].apply(str_to_num)\n",
    "        \n",
    "    return df\n",
    "\n",
    "def calculate_avg(df):\n",
    "    col_list = [col for col in df.columns if col.endswith('_value')]\n",
    "\n",
    "    for value_name in col_list:\n",
    "        for idx, row in df.iterrows():\n",
    "            values = row[value_name]\n",
    "            if values is not None:\n",
    "                df.at[idx, value_name] = np.mean(values)\n",
    "\n",
    "            else:\n",
    "                df.at[idx, value_name] = None\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## processing column data: annotations, categories\n",
    "\n",
    "def data_split(df, target_col):\n",
    "    exploded_df = df.explode(target_col).reset_index(drop=True)\n",
    "    exploded_df = pd.concat([exploded_df.drop([target_col], axis=1),\n",
    "                             exploded_df[target_col].apply(pd.Series)], axis=1)\n",
    "    \n",
    "    return exploded_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## processing column data: bbox, rest data\n",
    "\n",
    "def split_bbox(df):\n",
    "    df['bbox_x'] = df['bbox'].apply(lambda bbox: bbox[0])\n",
    "    df['bbox_y'] = df['bbox'].apply(lambda bbox: bbox[1])\n",
    "    df['bbox_width'] = df['bbox'].apply(lambda bbox: bbox[2])\n",
    "    df['bbox_height'] = df['bbox'].apply(lambda bbox: bbox[3])\n",
    "\n",
    "    return df\n",
    "\n",
    "def process_rest_values(df, class_kor, class_en):\n",
    "    df_cleaned = df.rename(columns={'images.fname':'file_name',\n",
    "                                    'images.width':'image_width',\n",
    "                                      'images.height':'image_height',\n",
    "                                        'images.disease_class':'class',\n",
    "                                          'images.disease_cause_method':'cause_method'})\n",
    "    \n",
    "    df_cleaned['cause_method']=df_cleaned['cause_method'].apply(lambda x: x.replace('칼슘부족','low_Ca'))\n",
    "    df_cleaned['cause_method']=df_cleaned['cause_method'].apply(lambda x: x.replace('질소부족','low_N'))\n",
    "    df_cleaned['cause_method']=df_cleaned['cause_method'].apply(lambda x: x.replace('수분제한','water_'))\n",
    "    df_cleaned['cause_method']=df_cleaned['cause_method'].apply(lambda x: x.replace('주입','_injection'))    \n",
    "    df_cleaned['cause_method']=df_cleaned['cause_method'].apply(lambda x: x.replace(class_kor,class_en))\n",
    "    df_cleaned['class']=df_cleaned['class'].apply(lambda x: x.replace(class_kor, class_en))\n",
    "\n",
    "    replace_values = {'잎': 'leaf', '줄기': 'stem', '과실': 'fruit', '화방': 'flower'}\n",
    "    df_cleaned['name'] = df_cleaned['name'].replace(replace_values, regex=True)\n",
    "    df_cleaned = df_cleaned.drop(['ir_value', 'tl_value', 'rp_value'], axis=1)\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define integrated functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# envrionments 컬럼 데이터 처리 통합 함수\n",
    "\n",
    "def process_col_environments(df, target_col, saving_col):\n",
    "    env_target, env_saving = target_col, saving_col\n",
    "    env_pandas, env_list = json_data_to_pandas(df, target_col=env_target, saving_col=env_saving)\n",
    "    env_values = extraction_env_values(env_pandas, env_list, env_saving)\n",
    "    env_values_num = string_to_number(env_values)\n",
    "    env_values_avg = calculate_avg(env_values_num)\n",
    "    \n",
    "    return env_values_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotations, categories 컬럼 데이터 처리 통합 함수\n",
    "\n",
    "def process_col_annotations_categories(df, target_col_1, saving_col_1, target_col_2, saving_col_2):\n",
    "    df_anno = df.drop(['categories'], axis=1)\n",
    "    df_cat = df[['images.fname', 'categories']].copy()\n",
    "    anno_target, anno_saving = target_col_1, saving_col_1\n",
    "    cat_target, cat_saving = target_col_2, saving_col_2\n",
    "\n",
    "    anno_pandas, _ = json_data_to_pandas(df_anno, anno_target, anno_saving)\n",
    "    cat_pandas, _ = json_data_to_pandas(df_cat, cat_target, cat_saving)\n",
    "\n",
    "    anno_split = data_split(anno_pandas, target_col=anno_saving)\n",
    "    anno_split_sel = anno_split.drop(['coordinates', 'area', 'isCrowd',\n",
    "                                      'id', 'image_id'],\n",
    "                                      axis=1)\n",
    "    cat_split = data_split(cat_pandas, target_col=cat_saving)\n",
    "    anno_split_sel['category_id'] = cat_split['id']\n",
    "    anno_split_sel['name'] = cat_split['name']\n",
    "\n",
    "    return anno_split_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## environments, annotations, categories 컬럼 모두 처리하는 종합 함수\n",
    "\n",
    "def label_preprocess(df, target_0, target_1, target_2, saving_0, saving_1, saving_2, class_kor, class_en):\n",
    "    processed_env = process_col_environments(df, target_0, saving_0)\n",
    "    processed_anno_cat = process_col_annotations_categories(processed_env, target_1, saving_1, target_2, saving_2)\n",
    "    processed_bbox = split_bbox(processed_anno_cat)\n",
    "    processed_data = process_rest_values(processed_bbox, class_kor, class_en)\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activate functions and check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### label data copy and merging\n",
    "\n",
    "input_path_1 = './data_raw/train_label/TL_01.딸기_001.설향_01.정상'\n",
    "input_path_2 = './data_raw/train_label/TL_01.딸기_001.설향_02.역병'\n",
    "input_path_3 = './data_raw/train_label/TL_01.딸기_001.설향_03.시들음병'\n",
    "input_path_4 = './data_raw/train_label/TL_01.딸기_001.설향_04.잎끝마름'\n",
    "input_path_5 = './data_raw/train_label/TL_01.딸기_001.설향_05.황화'\n",
    "output_path_1 = './data_raw/train_label/sampling_normal'\n",
    "output_path_2 = './data_raw/train_label/sampling_blight'\n",
    "output_path_3 = './data_raw/train_label/sampling_wilt'\n",
    "output_path_4 = './data_raw/train_label/sampling_scorch'\n",
    "output_path_5 = './data_raw/train_label/sampling_chlorosis'\n",
    "\n",
    "input_paths = [input_path_1, input_path_2, input_path_3, input_path_4, input_path_5]\n",
    "output_paths = [output_path_1, output_path_2, output_path_3, output_path_4, output_path_5]\n",
    "num_files = 12000\n",
    "\n",
    "copy_results = [copy_files(input_path, output_path, num_files) for input_path, output_path in zip(input_paths, output_paths)]\n",
    "\n",
    "folder_paths = [r'./data_raw/train_label/sampling_normal', r'./data_raw/train_label/sampling_blight',\n",
    "                r'./data_raw/train_label/sampling_wilt', r'./data_raw/train_label/sampling_scorch',\n",
    "                r'./data_raw/train_label/sampling_chlorosis']\n",
    "\n",
    "copy_results\n",
    "merged_normal = json_to_df(folder_paths[0])\n",
    "merged_blight = json_to_df(folder_paths[1])\n",
    "merged_wilt = json_to_df(folder_paths[2])\n",
    "merged_scorch = json_to_df(folder_paths[3])\n",
    "merged_chlorosis = json_to_df(folder_paths[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### image data copy and renameing\n",
    "\n",
    "src_path_1 = './data_raw/train_image/TS_01.딸기_001.설향_01.정상'\n",
    "src_path_2 = './data_raw/train_image/TS_01.딸기_001.설향_02.역병'\n",
    "src_path_3 = './data_raw/train_image/TS_01.딸기_001.설향_03.시들음병'\n",
    "src_path_4 = './data_raw/train_image/TS_01.딸기_001.설향_04.잎끝마름'\n",
    "src_path_5 = './data_raw/train_image/TS_01.딸기_001.설향_05.황화'\n",
    "dst_path_1 = './data_raw/train_image/image_sampling_normal'\n",
    "dst_path_2 = './data_raw/train_image/image_sampling_blight'\n",
    "dst_path_3 = './data_raw/train_image/image_sampling_wilt'\n",
    "dst_path_4 = './data_raw/train_image/image_sampling_scorch'\n",
    "dst_path_5 = './data_raw/train_image/image_sampling_chlorosis'\n",
    "\n",
    "src_paths = [src_path_1, src_path_2, src_path_3, src_path_4, src_path_5]\n",
    "dst_paths = [dst_path_1, dst_path_2, dst_path_3, dst_path_4, dst_path_5]\n",
    "df_list = [merged_normal, merged_blight, merged_wilt, merged_scorch, merged_chlorosis]\n",
    "\n",
    "for src, dst, data in zip(src_paths, dst_paths, df_list):\n",
    "    copy_images = copy_image_files(src, dst, data)\n",
    "    copy_images\n",
    "\n",
    "normal_en = rename_kor_en(merged_normal, kor='정상', en='normal', image_path=dst_path_1)\n",
    "blight_en = rename_kor_en(merged_blight, kor='역병', en='blight', image_path=dst_path_2)\n",
    "wilt_en = rename_kor_en(merged_wilt, kor='시들음병', en='wilt', image_path=dst_path_3)\n",
    "scorch_en = rename_kor_en(merged_scorch, kor='잎끝마름', en='scorch', image_path=dst_path_4)\n",
    "chlorosis_en = rename_kor_en(merged_chlorosis, kor='황화', en='chlorosis', image_path=dst_path_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### selecting columns\n",
    "\n",
    "col_selection = ['environments', 'annotations', 'categories', 'images.fname', 'images.width',\n",
    "                 'images.height', 'images.disease_class', 'images.disease_cause_method']\n",
    "\n",
    "normal_data = selecting_columns(normal_en, col_selection)\n",
    "blight_data = selecting_columns(blight_en, col_selection)\n",
    "wilt_data = selecting_columns(wilt_en, col_selection)\n",
    "scorch_data = selecting_columns(scorch_en, col_selection)\n",
    "chlorosis_data = selecting_columns(chlorosis_en, col_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### processing all target columns: environments, annotations, categories\n",
    "\n",
    "normal_preprocessed = label_preprocess(normal_data,\n",
    "                                       'environments', 'annotations', 'categories',\n",
    "                                       'env_values', 'anno_values', 'cat_values',\n",
    "                                       '정상', 'normal')\n",
    "blight_preprocessed = label_preprocess(blight_data,\n",
    "                                       'environments', 'annotations', 'categories',\n",
    "                                       'env_values', 'anno_values', 'cat_values',\n",
    "                                       '역병', 'blight')\n",
    "wilt_preprocessed = label_preprocess(wilt_data,\n",
    "                                     'environments', 'annotations', 'categories',\n",
    "                                     'env_values', 'anno_values', 'cat_values',\n",
    "                                     '시들음병', 'wilt')\n",
    "scorch_preprocessed = label_preprocess(scorch_data,\n",
    "                                       'environments', 'annotations', 'categories',\n",
    "                                       'env_values', 'anno_values', 'cat_values',\n",
    "                                       '잎끝마름', 'scorch')\n",
    "chlorosis_preprocessed = label_preprocess(chlorosis_data,\n",
    "                                          'environments', 'annotations', 'categories',\n",
    "                                          'env_values', 'anno_values', 'cat_values',\n",
    "                                          '황화', 'chlorosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging data and saving into csv files\n",
    "\n",
    "train_data = pd.concat([normal_preprocessed,\n",
    "                        blight_preprocessed,\n",
    "                        wilt_preprocessed,\n",
    "                        scorch_preprocessed,\n",
    "                        chlorosis_preprocessed],\n",
    "                        axis=0, ignore_index=True)\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train_data.to_csv('./data_preprocessed/train_label.csv', encoding='utf-8', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### label data copy and merging\n",
    "\n",
    "vl_input_path_1 = './data_raw/test_label/VL_01.딸기_001.설향_01.정상'\n",
    "vl_input_path_2 = './data_raw/test_label/VL_01.딸기_001.설향_02.역병'\n",
    "vl_input_path_3 = './data_raw/test_label/VL_01.딸기_001.설향_03.시들음병'\n",
    "vl_input_path_4 = './data_raw/test_label/VL_01.딸기_001.설향_04.잎끝마름'\n",
    "vl_input_path_5 = './data_raw/test_label/VL_01.딸기_001.설향_05.황화'\n",
    "vl_output_path_1 = './data_raw/test_label/sampling_normal'\n",
    "vl_output_path_2 = './data_raw/test_label/sampling_blight'\n",
    "vl_output_path_3 = './data_raw/test_label/sampling_wilt'\n",
    "vl_output_path_4 = './data_raw/test_label/sampling_scorch'\n",
    "vl_output_path_5 = './data_raw/test_label/sampling_chlorosis'\n",
    "\n",
    "vl_input_paths = [vl_input_path_1, vl_input_path_2, vl_input_path_3, vl_input_path_4, vl_input_path_5]\n",
    "vl_output_paths = [vl_output_path_1, vl_output_path_2, vl_output_path_3, vl_output_path_4, vl_output_path_5]\n",
    "vl_num_files = 500\n",
    "\n",
    "vl_copy_results = [copy_files(input_path, output_path, vl_num_files) for input_path, output_path in zip(vl_input_paths, vl_output_paths)]\n",
    "\n",
    "vl_folder_paths = [r'./data_raw/test_label/sampling_normal', r'./data_raw/test_label/sampling_blight',\n",
    "                r'./data_raw/test_label/sampling_wilt', r'./data_raw/test_label/sampling_scorch',\n",
    "                r'./data_raw/test_label/sampling_chlorosis']\n",
    "\n",
    "copy_results\n",
    "vl_merged_normal = json_to_df(vl_folder_paths[0])\n",
    "vl_merged_blight = json_to_df(vl_folder_paths[1])\n",
    "vl_merged_wilt = json_to_df(vl_folder_paths[2])\n",
    "vl_merged_scorch = json_to_df(vl_folder_paths[3])\n",
    "vl_merged_chlorosis = json_to_df(vl_folder_paths[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### image data copy and renameing\n",
    "\n",
    "vl_src_path_1 = './data_raw/test_image/VS_01.딸기_001.설향_01.정상'\n",
    "vl_src_path_2 = './data_raw/test_image/VS_01.딸기_001.설향_02.역병'\n",
    "vl_src_path_3 = './data_raw/test_image/VS_01.딸기_001.설향_03.시들음병'\n",
    "vl_src_path_4 = './data_raw/test_image/VS_01.딸기_001.설향_04.잎끝마름'\n",
    "vl_src_path_5 = './data_raw/test_image/VS_01.딸기_001.설향_05.황화'\n",
    "vl_dst_path_1 = './data_raw/test_image/image_sampling_normal'\n",
    "vl_dst_path_2 = './data_raw/test_image/image_sampling_blight'\n",
    "vl_dst_path_3 = './data_raw/test_image/image_sampling_wilt'\n",
    "vl_dst_path_4 = './data_raw/test_image/image_sampling_scorch'\n",
    "vl_dst_path_5 = './data_raw/test_image/image_sampling_chlorosis'\n",
    "\n",
    "vl_src_paths = [vl_src_path_1, vl_src_path_2, vl_src_path_3, vl_src_path_4, vl_src_path_5]\n",
    "vl_dst_paths = [vl_dst_path_1, vl_dst_path_2, vl_dst_path_3, vl_dst_path_4, vl_dst_path_5]\n",
    "vl_df_list = [vl_merged_normal, vl_merged_blight, vl_merged_wilt, vl_merged_scorch, vl_merged_chlorosis]\n",
    "\n",
    "for src, dst, data in zip(vl_src_paths, vl_dst_paths, vl_df_list):\n",
    "    vl_copy_images = copy_image_files(src, dst, data)\n",
    "    vl_copy_images\n",
    "\n",
    "vl_normal_en = rename_kor_en(vl_merged_normal, kor='정상', en='normal', image_path=vl_dst_path_1)\n",
    "vl_blight_en = rename_kor_en(vl_merged_blight, kor='역병', en='blight', image_path=vl_dst_path_2)\n",
    "vl_wilt_en = rename_kor_en(vl_merged_wilt, kor='시들음병', en='wilt', image_path=vl_dst_path_3)\n",
    "vl_scorch_en = rename_kor_en(vl_merged_scorch, kor='잎끝마름', en='scorch', image_path=vl_dst_path_4)\n",
    "vl_chlorosis_en = rename_kor_en(vl_merged_chlorosis, kor='황화', en='chlorosis', image_path=vl_dst_path_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### selecting columns\n",
    "\n",
    "col_selection = ['environments', 'annotations', 'categories', 'images.fname', 'images.width',\n",
    "                 'images.height', 'images.disease_class', 'images.disease_cause_method']\n",
    "\n",
    "vl_normal_data = selecting_columns(vl_normal_en, col_selection)\n",
    "vl_blight_data = selecting_columns(vl_blight_en, col_selection)\n",
    "vl_wilt_data = selecting_columns(vl_wilt_en, col_selection)\n",
    "vl_scorch_data = selecting_columns(vl_scorch_en, col_selection)\n",
    "vl_chlorosis_data = selecting_columns(vl_chlorosis_en, col_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### processing all target columns: environments, annotations, categories\n",
    "\n",
    "vl_normal_preprocessed = label_preprocess(vl_normal_data,\n",
    "                                       'environments', 'annotations', 'categories',\n",
    "                                       'env_values', 'anno_values', 'cat_values',\n",
    "                                       '정상', 'normal')\n",
    "vl_blight_preprocessed = label_preprocess(vl_blight_data,\n",
    "                                       'environments', 'annotations', 'categories',\n",
    "                                       'env_values', 'anno_values', 'cat_values',\n",
    "                                       '역병', 'blight')\n",
    "vl_wilt_preprocessed = label_preprocess(vl_wilt_data,\n",
    "                                     'environments', 'annotations', 'categories',\n",
    "                                     'env_values', 'anno_values', 'cat_values',\n",
    "                                     '시들음병', 'wilt')\n",
    "vl_scorch_preprocessed = label_preprocess(vl_scorch_data,\n",
    "                                       'environments', 'annotations', 'categories',\n",
    "                                       'env_values', 'anno_values', 'cat_values',\n",
    "                                       '잎끝마름', 'scorch')\n",
    "vl_chlorosis_preprocessed = label_preprocess(vl_chlorosis_data,\n",
    "                                          'environments', 'annotations', 'categories',\n",
    "                                          'env_values', 'anno_values', 'cat_values',\n",
    "                                          '황화', 'chlorosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging data and saving into csv files\n",
    "\n",
    "test_data = pd.concat([vl_normal_preprocessed,\n",
    "                        vl_blight_preprocessed,\n",
    "                        vl_wilt_preprocessed,\n",
    "                        vl_scorch_preprocessed,\n",
    "                        vl_chlorosis_preprocessed],\n",
    "                        axis=0, ignore_index=True)\n",
    "test_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test_data.to_csv('./data_preprocessed/test_label.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
